{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions to generate data using the GA\n",
    "\n",
    "This script is used to generate the alldata.csv file in the data folder of the following github repository: https://github.com/krl4005/RRC-ConductanceProfile-Project.git \n",
    "\n",
    "If you want to generate new data, run the run_ga.sh script (which calls the run_ga.py file). This could be done by following these steps: \n",
    "\n",
    "* type *sbatch run_ga.sh './data/trial1_'* (the path in quotes represents where and to what name you want to save the data to.)\n",
    "* This should take about 16 hours and when done it will save to the data folder. \n",
    "* Using that new data, we can use this script to generate a new all_data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT FUNCTIONS\n",
    "import pandas as pd\n",
    "from important_functions import generate_alldata, get_cond_data, get_robust_data, get_local_sensitivity, get_rrc_data, get_baseline_torord_data, get_ind\n",
    "\n",
    "save_data_to = './data/'\n",
    "get_data_from = './data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate all_data.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the generate_alldata function\n",
    "all_trials = generate_alldata(get_data_from, trials = ['trial1', 'trial2', 'trial3', 'trial4', 'trial6', 'trial7', 'trial8'])\n",
    "\n",
    "# This selects and organizes specific columns since the file is too large when saving all the data.\n",
    "# It then saves the data to the RRC Conductance Profile Repo\n",
    "all_data = all_trials[['gen', 'trial', 'i_cal_pca_multiplier', 'i_ks_multiplier', 'i_kr_multiplier', 'i_nal_multiplier', 'i_na_multiplier', 'i_to_multiplier', 'i_k1_multiplier', 'i_NCX_multiplier', 'i_nak_multiplier', 'fitness', 'rrc', 'rrc_error', 'total_feature_error', 'total_morph_error', 'apd90_AP4']] #'apd90_AP4_error'\n",
    "all_data.to_csv(save_data_to+'all_data.csv.bz2', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate best_data.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_data = all_trials[(all_trials['fitness']<2800) & (all_trials['total_morph_error']==0) & (all_trials['total_feature_error']==0)]\n",
    "best_data.reset_index(inplace=True)\n",
    "best_data.to_csv(save_data_to+'best_data.csv.bz2', index=False)\n",
    "best_data.to_csv('./data/best_data.csv.bz2', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to generate the fig2_data.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2_data = all_trials[(all_trials['gen']==0) | (all_trials['gen']==30) | (all_trials['gen']==99)]\n",
    "fig2_data = fig2_data[['gen', 'trial', 'fitness', 'rrc', 't', 'v', 'cai']]\n",
    "fig2_data.to_csv(save_data_to+'fig2_data.csv.bz2', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate cond_data.pkl and robust_data.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cond_data(best_data_path = get_data_from+'best_data.csv.bz2', save_to = save_data_to+'cond_data.pkl') \n",
    "get_robust_data(best_data_path = get_data_from+'best_data.csv.bz2', save_to = save_data_to+'robust_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate local sensitivity & RRC data: apd_rrc_sens_baseline.csv, apd_rrc_sens_opt.csv, apd_rrc_sens_grandi.csv, and rrc_data.csv\n",
    "\n",
    "This could be run locally but it takes A LONGGGGG TIME (like a few hours). If you would like to run this data on the cluster (which only takes about 20 minutes) you could using the *run_get_data.sh* file. If you do not want to recollect all this data just comment out the lines you do not need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity data for baseline Grandi Model\n",
    "get_local_sensitivity(best_data_path={'i_cal_pca_multiplier':1, 'i_ks_multiplier':1, 'i_kr_multiplier':1, 'i_nal_multiplier':0, 'i_na_multiplier':1, 'i_to_multiplier':1, 'i_k1_multiplier':1, 'i_NCX_multiplier':1, 'i_nak_multiplier':1}, save_to = save_data_to+'sens_grandi.csv.bz2', model = 'grandi_flat.mmt', stim = 1, length = 5)\n",
    "\n",
    "# Sensitivity data for optimized ToR-ORd Model\n",
    "get_local_sensitivity(best_data_path=get_data_from+'best_data.csv.bz2', save_to = save_data_to+'sens_opt.csv.bz2')\n",
    "\n",
    "# Sensitivity data for baseline ToR-ORd Model\n",
    "get_local_sensitivity(best_data_path=get_ind(), save_to = save_data_to+'sens_baseline.csv.bz2')\n",
    "\n",
    "# RRC data for baseline ToR-ORd Model and all 220 optimized models\n",
    "get_rrc_data(best_data_path=get_data_from+'best_data.csv.gz', save_to = save_data_to+'rrc_data.csv.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate baseline_torord_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_baseline_torord_data(save_to= './data/baseline_torord_data.csv.bz2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
